---
name:  geocloud008
title: 地球云计算 008：奋进号历险记（中）
date:  2017-4-10
tags: 地球云计算
---
<!-- more -->
![](/cnblog/uploads/geocloud008.jpg)

2013年冬，我搬家到亚省，是一个 NASA 项目，全球高分辨率耕地制图（GFSAD30），这件事情有别于此前工作的地方在于，区域性研究往往基于特定的先验知识，就比如说，你想研究北京大兴的西瓜地，那么跑到大兴去吃两天西瓜，四下里看一看，也就可以了，甚至你再去保定跑两趟，说不定就可以了解到华北的西瓜是个什么情况，至少是大致上。但你肯定不会以为你手头的数据可以把新疆的西瓜都代表进来。事实上，全球各地，还有你没听说过的很多地方都种着西瓜，这样你不知道那里的西瓜长成什么样了。

这是种繁琐的说法，简单的说法就是，为了了解数据的总体分布或特征（全球的西瓜），我们需要一些数据探索手段。否则的话，就只能守着一些局部知识（大兴的西瓜）过日子，而局部知识有多大的适用范围，能代表总体分布里的百分之多少，也是需要了解的内容。

Landsat遥感卫星日夜监测地表长达四十年，已经建立起一套地表观测记录，这套数据去掉云，留下晴好的部分，再使用一些数据处理技术进行填补，可以得到每个月的全球多波段影像。现在，假设我们已经知道了全球耕地的分布（以前 NASA有一些地表覆盖类别的数据，并不准确但可以作为参考），怎么样组织我们的采样方案，在复杂的地区多采些样，在简单的地区少采些样，使得采样的结果更接近于全球耕地的总体分布？

当然，实际上的采样方案是一个多目标的的妥协结果，要考虑到具体采样的难度、时间和经济费用，但是，首先需要一个对全球耕地的分布刻画：哪里种类多，地块破碎、分布；哪里种类单一，地块集中。这样的话，对全球遥感数据做一次聚类分析，就是首要处理的问题，对于采样，数据挖掘，分类器设计，能够提供给我们很多的信息。

聚类分析是遥感图像处理里的基本方法，问题在于如何处理如此大的数据（全球单景影像总量达 10TB）。一个简单的办法就是抽稀了后再去聚类，把 30m 的数据变成 1km再聚类，数据量少了，也能提供一些数据。但对于数据探索而言，这样就失去了意义，因为你不能假定抽稀了以后总体分布不变。真实地表不具有这种连续性。比如，很多耕地都分布在河流沿岸，三角洲处，你一抽就可能把它们全跳过去了。

那么一般的分布化，把这么多数据切片，比如说切成 2GB，聚完类后再拼接起来，可不可以呢？

这是不行的。我先简单介绍一下聚类算法。其原理简单来说就是，想象你有一堆星星需要聚成不同名字的星团，想要的聚类效果就是“星团内的星星都足够近，星团间的星星都足够远”。首先你要确定所有的星星最后聚成几类，然后挑选几个点作为初始中心点，再然后依据预先定好的启发式算法（heuristic+algorithms）给数据点做迭代重置（iterative+relocation），直到最后到达“类内的点都足够近，类间的点都足够远”的目标效果。也正是根据所谓的“启发式算法”，形成了k-means算法及其变体包括k-medoids、k-modes、k-medians、kernel+k-means等算法。另外，很多教程都告诉我们Partition-based+methods聚类多适用于中等体量的数据集，但我们也不知道“中等”到底有多“中”，所以不妨理解成，数据集越大，越有可能陷入局部最小。所以，我们还需要试探性地选择初始类中心，即所谓的 kmean++。

![](/uploads/geocloud008a.png)

具体说来，首先随机选取k个宇宙中的点（或者k个星星）作为k个星团的质心，然后第一步对于每一个星星计算其到k个质心中每一个的距离，然后选取距离最近的那个星团作为所属类，这样经过第一步每一个星星都有了所属的星团；第二步对于每一个星团，重新计算它的质心（对里面所有的星星坐标求平均）。重复迭代第一步和第二步直到质心不变或者变化很小。也就是说，在这个过程中，所有的星星坐标（每个像素的多波段信息）都必须是全局可以见的，无法分布化，除非你设计出极为复杂的索引系统和聚类合并算法。

奋进号，买卖上门了！

有了奋进号这种神器，心中自然狂野。为了把TB 级数据送入奋进号聚类，我需要把计算和I/O都分布化，否则数据的读写会成为新的瓶颈。我先是找到了parallel-netcdf库，由西北大学和阿贡国家实验室联合开发的，是一种高速并行读写库。pnetcdf 的开发者之一，Wei-keng Liao，在 pnetcdf 上实现了一个 k-means。他的学生 Jing Zhang 用 MPI 实际了并行 K-means，但是没有跑过TB级数据。MPI 看起来不错，在奋进号上也有优化后的编译器。我下载了并行 K-means 的代码，第一步先把地址长度从 32 改成 64（必须的嘛），然后——

![](/uploads/geocloud008b.jpg)

然后程序就崩了。

西北大学的Wei-keng Liao教授温文尔雅，给我很多适时的支援。在他的帮助下，我在奋进号上布署了一套海量数据的聚类器。用200个 CPU把2TB 的数据送入奋进号，2小时后，奋进号吐出了结果。